---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
from CitizenUAV.models import InatClassifier
from CitizenUAV.data import InatDataModule
from CitizenUAV.processes import approximate_content, approximate_style
from torch import nn
from torchvision.transforms.functional import to_pil_image
from matplotlib import pyplot as plt
from CitizenUAV.io_utils import get_pid_from_path
import torch
from torch import optim
from tqdm import tqdm
import numpy as np
```

```{python}
model_path = '/home/ndettmer/experiments/ma/classification/maize_ternary/lightning_logs/version_0/checkpoints/epoch=49-step=43200.ckpt'
cnn = InatClassifier.load_from_checkpoint(model_path)
```

```{python}
dm = InatDataModule('/home/ndettmer/ssd_data/inat_subsets/maize_ternary', normalize=True, batch_size=1, min_distance=5)
cnn.eval()
max_conf = 0
sample_idx = None
for i in tqdm(np.random.choice(range(len(dm.ds)), size=len(dm.ds))):
    img, t = dm.ds[i]
    if t != dm.ds.dataset.class_to_idx['zea mays']:
        continue
    with torch.no_grad():
        y_hat = cnn(img.unsqueeze(0))
    pred = torch.argmax(y_hat).item()
    conf = torch.max(y_hat).item()
    if pred == t:
        if conf == 1:
            sample_idx = i
            break
        if conf > max_conf:
            max_conf = conf
            sample_idx = i
```

```{python}
dm = InatDataModule('/home/ndettmer/ssd_data/inat_subsets/maize_ternary', normalize=False, batch_size=1, min_distance=5)
norm = dm.get_normalize_module()
maize_sample = dm.ds[sample_idx][0]
```

```{python}
plt.figure()
plt.subplot(1, 2, 1)
plt.imshow(to_pil_image(maize_sample))
plt.subplot(1, 2, 2)
plt.imshow(to_pil_image(norm(maize_sample)))
plt.show()
```

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*tH9evuOFqk8F41FG.png)


I want to visualize the outputs of Stages 2, 3, 4 and 5.
- Stage 2: `model.feature_extractor[4]`
- Stage 3: `model.feature_extractor[5]`
- Stage 4: `model.feature_extractor[6]`
- Stage 5: `model.feature_extractor[7]`

```{python}
stage_2 = nn.Sequential(norm, *list(cnn.feature_extractor.children())[:5])
stage_3 = nn.Sequential(norm, *list(cnn.feature_extractor.children())[:6])
stage_4 = nn.Sequential(norm, *list(cnn.feature_extractor.children())[:7])
stage_5 = nn.Sequential(norm, *list(cnn.feature_extractor.children())[:8])
```

```{python}
x = torch.rand(maize_sample.shape)
output = approximate_content(x, stage_2, maize_sample)
content_repr = to_pil_image(output.squeeze(0))
plt.imshow(content_repr)
```

```{python}
x = torch.rand(maize_sample.shape)
output = approximate_style(x, stage_4, maize_sample, num_steps=500)
style_repr = to_pil_image(output.squeeze(0))
plt.imshow(style_repr)
```

```{python}

```
