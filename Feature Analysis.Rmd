---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
from CitizenUAV.models import InatSequentialClassifier
from CitizenUAV.data import InatDataModule
from CitizenUAV.processes import optimize_image_resnet
from torch import nn
from torchvision.transforms.functional import to_pil_image
from matplotlib import pyplot as plt
from CitizenUAV.io_utils import get_pid_from_path
import torch
from torch import optim
from tqdm import tqdm
import numpy as np
import pandas as pd
import os
```

```{python}
result_dir = '/home/ndettmer/experiments/ma/classification/maize_ternary/predictions/style_transfer/'
dm = InatDataModule('/home/ndettmer/ssd_data/inat_subsets/maize_ternary_manual_preselect', normalize=False, batch_size=1, min_distance=5, return_path=True)
norm = dm.get_normalize_module()
model_version = 'version_4'
cnn = InatSequentialClassifier.load_from_checkpoint(f'/home/ndettmer/experiments/ma/classification/maize_ternary_manual_preselect/lightning_logs/{model_version}/checkpoints/epoch=49-step=43200.ckpt')
cnn.eval()

pred_df = pd.read_csv(f'/home/ndettmer/experiments/ma/classification/maize_ternary_manual_preselect_old/predictions/inat/{model_version}/23-05-18_15-21_predictions.csv')
```

```{python}
def get_safe_pred_sample(label):
    subset = pred_df[(pred_df.target_text == label) & (pred_df.prediction_text == label)]
    max_prob = subset[f"{label}_prob"].max()
    subset = subset[subset[f"{label}_prob"] == max_prob]
    if len(subset) > 0:
        return subset.sample()
    print(f"No sample found for label {label}")
    return None
```

```{python}
maize_sample_pid = get_safe_pred_sample('zea mays').pid.values[0]
maize_sample, _, _ = dm.ds.dataset.get_item_by_pid(maize_sample_pid)

weed_sample_pid = get_safe_pred_sample('weed').pid.values[0]
weed_sample, _, _ = dm.ds.dataset.get_item_by_pid(weed_sample_pid)

soil_sample_pid = get_safe_pred_sample('soil').pid.values[0]
soil_sample, _, _ = dm.ds.dataset.get_item_by_pid(soil_sample_pid)
```

```{python}
maize_sample_pid, weed_sample_pid, soil_sample_pid
```

```{python}
plt.figure(figsize=(15, 15))
plt.subplot(3, 2, 1)
plt.imshow(to_pil_image(maize_sample))
plt.subplot(3, 2, 2)
plt.imshow(to_pil_image(norm(maize_sample)))
plt.subplot(3, 2, 3)
plt.imshow(to_pil_image(weed_sample))
plt.subplot(3, 2, 4)
plt.imshow(to_pil_image(norm(weed_sample)))
plt.subplot(3, 2, 5)
plt.imshow(to_pil_image(soil_sample))
plt.subplot(3, 2, 6)
plt.imshow(to_pil_image(norm(soil_sample)))
plt.show()
```

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*tH9evuOFqk8F41FG.png)


I want to visualize the outputs of Stages 2, 3, 4 and 5.
- Stage 2: `model.feature_extractor[4]`
- Stage 3: `model.feature_extractor[5]`
- Stage 4: `model.feature_extractor[6]`
- Stage 5: `model.feature_extractor[7]`

<!-- #region jp-MarkdownHeadingCollapsed=true tags=[] jp-MarkdownHeadingCollapsed=true -->
## Content and Style
<!-- #endregion -->

Stage 3 Seems to be better for content representation! Better segmentation!


### Maize

```{python}
output = optimize_image_resnet(cnn, [4, 5], dm.get_normalize_module(), maize_sample, 'ContentLoss')
content_repr = to_pil_image(output.squeeze(0))

plt.figure(figsize=(10, 10))
plt.subplot(1, 2, 1)
plt.imshow(content_repr)
plt.subplot(1, 2, 2)
plt.imshow(to_pil_image(maize_sample))
plt.savefig(f'{result_dir}/{maize_sample_pid}_{model_version}_content_repr.png')
```

```{python}
output = optimize_image_resnet(cnn, [4, 5, 6, 7], dm.get_normalize_module(), maize_sample, 'StyleLoss', num_steps=500)
style_repr = to_pil_image(output.squeeze(0))
plt.figure()
plt.imshow(style_repr)
plt.savefig(f'{result_dir}/{maize_sample_pid}_{model_version}_style_repr.png')
```

### Weed

```{python}
output = optimize_image_resnet(cnn, [4, 5], dm.get_normalize_module(), weed_sample, 'ContentLoss')
content_repr = to_pil_image(output.squeeze(0))

plt.figure(figsize=(10, 10))
plt.subplot(1, 2, 1)
plt.imshow(content_repr)
plt.subplot(1, 2, 2)
plt.imshow(to_pil_image(weed_sample))
plt.savefig(f'{result_dir}/{weed_sample_pid}_{model_version}_content_repr.png')
```

```{python}
output = optimize_image_resnet(cnn, [4, 5, 6, 7], dm.get_normalize_module(), weed_sample, 'StyleLoss', num_steps=500)
style_repr = to_pil_image(output.squeeze(0))
plt.figure()
plt.imshow(style_repr)
plt.savefig(f'{result_dir}/{weed_sample_pid}_{model_version}_style_repr.png')
```

### Soil

```{python}
output = optimize_image_resnet(cnn, [4, 5], dm.get_normalize_module(), soil_sample, 'ContentLoss')
content_repr = to_pil_image(output.squeeze(0))

plt.figure(figsize=(10, 10))
plt.subplot(1, 2, 1)
plt.imshow(content_repr)
plt.subplot(1, 2, 2)
plt.imshow(to_pil_image(soil_sample))
plt.savefig(f'{result_dir}/{soil_sample_pid}_{model_version}_content_repr.png')
```

```{python}
output = optimize_image_resnet(cnn, [4, 5, 6, 7], dm.get_normalize_module(), soil_sample, 'StyleLoss', num_steps=500)
style_repr = to_pil_image(output.squeeze(0))
plt.figure()
plt.imshow(style_repr)
plt.savefig(f'{result_dir}/{soil_sample_pid}_{model_version}_style_repr.png')
```

## Feature Maps

```{python}
stage_2 = nn.Sequential(*list(cnn.feature_extractor[:5]))
```

```{python}
stage_2.eval()
with torch.no_grad():
    fms = stage_2(maize_sample.unsqueeze(0))
```

```{python}
fms = fms.squeeze(0)
n_maps = fms.shape[0]
ax_len = int(np.sqrt(n_maps))

fig, axs = plt.subplots(ax_len, ax_len, figsize=(20, 20))
for i in range(n_maps):
    fm = fms[i]
    axs[i % ax_len, i // ax_len].imshow(to_pil_image(fm))
    axs[i % ax_len, i // ax_len].set_title(i)
    
plt.show()
```

```{python}
max_activation = torch.argmax(torch.sum(fms, dim=(1,2)))
```

```{python}
max_activation
```

```{python}
stage_3 = nn.Sequential(*list(cnn.feature_extractor[:6]))
```

```{python}
stage_3.eval()
with torch.no_grad():
    fms = stage_3(maize_sample.unsqueeze(0))
```

```{python}
fms = fms.squeeze(0)
n_maps = fms.shape[0]
ax_len = int(np.ceil(np.sqrt(n_maps)))

fig, axs = plt.subplots(ax_len, ax_len, figsize=(20, 20))
for i in range(n_maps):
    fm = fms[i]
    try:
        axs[i % ax_len, i // ax_len].imshow(to_pil_image(fm))
        axs[i % ax_len, i // ax_len].set_title(i)
    except IndexError:
        print(i)
        raise
    
plt.show()
```

```{python}
max_activation = torch.argmax(torch.sum(fms, dim=(1,2)))
```

```{python}
max_activation
```

NOTE: Let's try neuron 39 of stage 2 for now. 

```{python}

```
